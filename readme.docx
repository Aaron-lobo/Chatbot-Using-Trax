Name : Chatbot Using Trax
Scope: The current unprecedented pandemic has forced us to be distant and dependent on various technologies for communication. In times like these having something that can substitute for human interaction is not complementary but vital. We are focusing on creating a multi domain chatbot that can maintain conversations longer and is human-like.

Software Requirements :  
1: Trax:  Trax is a deep-learning library focused on clear code and speed and is actively used and maintained by the Google Brain team. It includes basic models (like ResNet, LSTM, Transformer, and R.L. algorithms (like REINFORCE, A2C, P.P.O.). 
2: NumPy: Numpy is a python library used for working with arrays. Numpy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of highlevel mathematical functions to operate on these arrays. MoreoverNumpy forms the foundation of the Machine Learning stack.
3: Pandas: Pandas is a software library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series.
4: Scikit : Scikit-learn is a free machine learning library for Python. It features various algorithms like support vector machine, random forests, and k-neighbours, and it also supports Python numerical and scientific libraries like NumPy and SciPy. The sklearn library contains a lot of efficient tools for machine learning and statistical modeling including classification, regression, clustering and dimensionality reduction. It is used to build machine learning models .
5: Google Colaboratory :Colab notebooks allow you to combine executable code and rich text in a single document, along with images, HTML, LaTeX and more. When you create your own Colab notebooks, they are stored in your Google Drive account. You can easily share your Colab notebooks with co-workers or friends, allowing them to comment on your notebooks or even edit them.

Language used : Python 3 
Steps involved :
1: Firstly, we load all the required and important libraries to work with, importing libraries.

2: Importing all the files that we will be using to work with our model.

3: Loading our corpus/dataset - MultiWOZ -- A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling

4: Processing the data for Reformer inputs: split the list to a train and eval dataset, Tokenizing, batching with bucketing, we will define our data pipeline for tokenizing and batching our data. We will bucket by length and also have an upper bound on the token length.

5: After processing and cleaning our data, we define our model, and we are using the Reversible layers, When running large deep models, you will often run out of memory as each layer allocates memory to store activations for use in backpropagation. To save this resource, you need to be able to recompute these activations during the backward pass without storing them during the forward pass. That is why we use reversible layers. Reversible layers and randomnessÂ¶
This is why we were are using fastmath's random functions and keys. Utilizing the same key, trax.fastmath.random.uniform() will return the same values. This is required for the backward pass to return the correct layer inputs when random noise is introduced in the layer.

6: Training the ReformerLM: We will now proceed to training your model.There are two main componenets that differentiate it from the standard Transformer, LSH in and reversible layers, we use the pre-built model already implemented in Trax.

7:Decoding and Word generation: returns a generator that predicts the next word of the conversation.

8:Finally, we can enter in a sentence and see how the model genreates the conversation further.



